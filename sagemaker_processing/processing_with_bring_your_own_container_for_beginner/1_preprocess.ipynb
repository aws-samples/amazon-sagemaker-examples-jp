{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker processing を利用して前処理を行う(処理時間10分弱程度)\n",
    "\n",
    "## 処理概要\n",
    "\n",
    "1. 前処理用コンテナの作成(詳細は[こちら](./container/Dockerfile))\n",
    "2. 前処理(詳細は[こちら](./container/preprocess_code/preprocess.py))をキック\n",
    "    1. S3 から前処理用コンテナに先程作成した zip ファイルをダウンロード(自動)\n",
    "    2. zip ファイルを解凍\n",
    "    3. 画像を開いてヒストグラム平坦化\n",
    "    4. numpy array に格納\n",
    "    5. npy ファイルを出力\n",
    "    6. 前処理用コンテナから S3 にデータをアップロード(自動)\n",
    "3. 前処理した結果を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](media/1_preprocess.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "print(f'Current sagemaker Version ={sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注） このノートブックでは SageMaker SDK が 2.19.0 以上で動作します。上記の出力結果がそれ以前のバージョンになった際は、下記のセルの#を削除（コメントアウトを解除）して実行、Jupyterカーネルを再起動し、再度上記のセルを実行し、バージョンがアップデートされたことを確認してください。カーネルが再起動されない場合は、SageMaker SDK バージョン更新が反映されません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U --quiet \"sagemaker>=2.19.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用するライブラリ等の読み込みと設定ファイルの読み込み\n",
    "自前のコンテナを SageMaker Processer で使うのと、その結果確認などに使うライブラリを事前に読み込む。また、[0_data_preparation.ipynb](./0_data_preparation.ipynb)の処理結果の格納場所などを引き継ぐため [setting.yaml](./setting.yaml) も読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.s3 import parse_s3_url\n",
    "import yaml,boto3, io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "role = get_execution_role()\n",
    "with open('./setting.yaml', 'r') as yml:\n",
    "    config = yaml.load(yml)\n",
    "name = config['name']\n",
    "zip_dataset_s3_uri = config['zip_dataset_s3_uri']\n",
    "timestamp = config['timestamp']\n",
    "print(f'role: {role}')\n",
    "print(f'name: {name}')\n",
    "print(f'zip_dataset_s3_uri: {zip_dataset_s3_uri}')\n",
    "print(f'timestamp: {timestamp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理用コンテナの作成\n",
    "* SageMaker では組み込みコンテナとして [Apache Spark](https://docs.aws.amazon.com/sagemaker/latest/dg/use-spark-processing-container.html) と [scikit-learn](https://docs.aws.amazon.com/sagemaker/latest/dg/use-scikit-learn-processing-container.html) があるが、画像処理を扱うためのコンテナがない(scikit-image, opencv, pillow など)\n",
    "* bring your own container することは可能なので、イメージを[作成](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-container-run-scripts.html)する\n",
    "* SageMaker Notebook では Docker がプリインストールされているのでそのまま利用する\n",
    "    1. ローカルでイメージをビルドする\n",
    "    2. Elastic Container Registry の リポジトリにイメージを push する\n",
    "    3. push した Image を利用して前処理を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image のビルド\n",
    "%cd container\n",
    "!docker build -t sagemaker-tf-handson-{name}-{timestamp} .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "tag = ':latest'\n",
    "\n",
    "ecr_repository = f'sagemaker-tf-handson-{name}-{timestamp}'\n",
    "image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{ecr_repository+tag}'\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t {ecr_repository} .\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print(f'コンテナは {image_uri} へ登録されています。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor インスタンス作成\n",
    "前処理を行うためのプロセッサーインスタンスを作成して、ジョブを開始する。 processor が処理を行う際のディレクトリとジョブ名を予め設定する（ジョブをキックするときに引数で指定する）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_input_dir = '/opt/ml/processing/input'\n",
    "processing_output_train_dir = '/opt/ml/processing/train'\n",
    "processing_output_test_dir = '/opt/ml/processing/test'\n",
    "job_name = f'sagemaker-preprocess-handson-{name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理を開始する\n",
    "前処理を行うコードを確認する。前処理を行うコードは `./preprocess_script/preprocess.py` に格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./preprocess_script/preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自前の Docker イメージで処理するための ScriptProcessor クラスから processor インスタンスを生成する。 `image_uri ` に先程 `push` したイメージの URI を指定する。また、今回作成した イメージは `python3` で Python 3.7 へパスが通っているため、command に `python3` を指定する。\n",
    "詳細は [ScriptProcessor]() を参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(base_job_name=job_name,\n",
    "                                   image_uri=image_uri,\n",
    "                                   command=['python3'],\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.c5.xlarge'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processor インスタンスを生成したら、 `run` メソッドで SageMaker Processing を走らせる。 `code` 引数に処理が書かれている .py ファイルを指定するが、S3 のパスでも良い。複数人で開発する際には、独自のスクリプトが乱立しやすいので、 S3 のパスを指定するか、 github や codecommit などのリポジトリから pull して使うか、Docker イメージに内包させて、code 引数で指定する.py ファイルには内包したスクリプトをキックさせるだけにする、など運用を考慮するとよい。arguments 引数で処理スクリプトに値を引き継ぎできる。\n",
    "\n",
    "詳細は[こちら](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html?highlight=ScriptProcessor#sagemaker.processing.ScriptProcessor.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zip ファイルを解凍してヒストグラム平坦化してnpyファイルにまとめる前処理を実行\n",
    "processor.run(code='./preprocess_script/preprocess.py', # S3 の URI でも可\n",
    "                     inputs=[ProcessingInput(source=zip_dataset_s3_uri,destination=processing_input_dir)],\n",
    "                     outputs=[\n",
    "                         ProcessingOutput(output_name='train',source=processing_output_train_dir),\n",
    "                         ProcessingOutput(output_name='test',source=processing_output_test_dir)],\n",
    "                      arguments=[\n",
    "                          '--hist-flatten', 'True',\n",
    "                          '--input-dir',processing_input_dir,\n",
    "                          '--output-train-dir',processing_output_train_dir,\n",
    "                          '--output-test-dir',processing_output_test_dir\n",
    "                      ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe メソッドを利用することでジョブの実行結果（データの出力先など）がわかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジョブの詳細を確認(前処理結果の格納先がわかる)\n",
    "processor_description = processor.jobs[-1].describe()\n",
    "print(processor_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行結果確認\n",
    "S3 に処理結果が格納されている。今回は npy ファイルを出力する処理のため、numpy でロードできるか、またその結果を目視で確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_uri = processor_description['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "test_data_uri = processor_description['ProcessingOutputConfig']['Outputs'][1]['S3Output']['S3Uri']\n",
    "print(f'train_data_uri: {train_data_uri}')\n",
    "print(f'test_data_uri: {test_data_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket,train_key = parse_s3_url(train_data_uri)\n",
    "bucket,test_key = parse_s3_url(test_data_uri)\n",
    "s3 = boto3.client('s3')\n",
    "obj_list=s3.list_objects_v2(Bucket=bucket, Prefix=train_key)\n",
    "file=[]\n",
    "for contents in obj_list['Contents']:\n",
    "    file.append(contents['Key'])\n",
    "obj_list=s3.list_objects_v2(Bucket=bucket, Prefix=test_key)\n",
    "for contents in obj_list['Contents']:\n",
    "    file.append(contents['Key'])\n",
    "\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x で100 番目のデータのみを確認\n",
    "res = boto3.client('s3').get_object(Bucket = bucket, Key = file[0])[\"Body\"].read()\n",
    "train_x = np.load(io.BytesIO(res))\n",
    "plt.imshow(train_x[100,:,:,0],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
