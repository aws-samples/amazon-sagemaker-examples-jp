{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker processing を利用して前処理を行う(処理時間10分弱程度)\n",
    "\n",
    "## 処理概要\n",
    "\n",
    "1. 前処理用コンテナの作成(詳細は[こちら](./container/Dockerfile))\n",
    "2. 前処理(詳細は[こちら](./container/preprocess_code/preprocess.py))をキック\n",
    "    1. S3 から前処理用コンテナに先程作成した zip ファイルをダウンロード(自動)\n",
    "    2. zip ファイルを解凍\n",
    "    3. 画像を開いてヒストグラム平坦化\n",
    "    4. numpy array に格納\n",
    "    5. npy ファイルを出力\n",
    "    6. 前処理用コンテナから S3 にデータをアップロード(自動)\n",
    "3. アップロードしたデータの URI を設定ファイルに書き込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](media/1_preprocess.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook のセルの横方向の表示範囲を広げる\n",
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用するライブラリ等の読み込みと設定ファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "import yaml\n",
    "role = get_execution_role()\n",
    "with open('./setting.yaml', 'r') as yml:\n",
    "    config = yaml.load(yml)\n",
    "name = config['name']\n",
    "zip_dataset_s3_uri = config['zip_dataset_s3_uri']\n",
    "timestamp = config['timestamp']\n",
    "print(f'role: {role}')\n",
    "print(f'name: {name}')\n",
    "print(f'zip_dataset_s3_uri: {zip_dataset_s3_uri}')\n",
    "print(f'timestamp: {timestamp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理用コンテナの作成\n",
    "* SageMaker ではビルトインコンテナとして [Apache Spark](https://docs.aws.amazon.com/sagemaker/latest/dg/use-spark-processing-container.html) と [scikit-learn](https://docs.aws.amazon.com/sagemaker/latest/dg/use-scikit-learn-processing-container.html) のコンテナがあるが、画像処理を扱うためのコンテナがない(scikit-image, opencv, pillow など)\n",
    "* bring your own container することは可能なので、Image を[作成](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-container-run-scripts.html)する\n",
    "* SageMaker Notebook では Docker がプリインストールされているのでそのまま利用する\n",
    "    1. ローカルで Image をビルドする\n",
    "    2. Elastic Container Registry の リポジトリに Image を push する\n",
    "    3. push した Image を利用して前処理を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image のビルド\n",
    "%cd container\n",
    "!docker build -t sagemaker-tf-handson-{name}-{timestamp} .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "tag = ':latest'\n",
    "\n",
    "ecr_repository = f'sagemaker-tf-handson-{name}-{timestamp}'\n",
    "image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{ecr_repository+tag}'\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t {ecr_repository} .\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print(f'コンテナは {image_uri} へ登録されています。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor インスタンス作成\n",
    "前処理を行うためのプロセッサーインスタンスを作成して、ジョブを開始する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_input_dir = '/opt/ml/processing/input'\n",
    "processing_output_train_dir = '/opt/ml/processing/train'\n",
    "processing_output_test_dir = '/opt/ml/processing/test'\n",
    "job_name = f'sagemaker-preprocess-handson-{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ScriptProcessor(base_job_name=job_name,\n",
    "                                   image_uri=image_uri,\n",
    "                                   command=['python3'],\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.c5.xlarge'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理を開始する\n",
    "\n",
    "#### オレオレ前処理スクリプトの防ぎ方 3 例\n",
    "* docker コンテナにスクリプトを入れ込み、起動コードにはそのスクリプトを呼び出す形を取る\n",
    "* S3 のパスを指定する\n",
    "* run する前に git pull するシェルスクリプトなどを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize ./preprocess_script/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zip ファイルを解凍してヒストグラム平坦化してnpyファイルにまとめる前処理\n",
    "processor.run(code='./preprocess_script/preprocess.py', # S3 の URI でも可\n",
    "                     inputs=[ProcessingInput(source=zip_dataset_s3_uri,destination=processing_input_dir)],\n",
    "                     outputs=[\n",
    "                         ProcessingOutput(output_name='train',source=processing_output_train_dir),\n",
    "                         ProcessingOutput(output_name='test',source=processing_output_test_dir)],\n",
    "                      arguments=[\n",
    "                          '--hist-flatten', 'True',\n",
    "                          '--input-dir',processing_input_dir,\n",
    "                          '--output-train-dir',processing_output_train_dir,\n",
    "                          '--output-test-dir',processing_output_test_dir\n",
    "                      ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジョブの詳細を確認(前処理結果の格納先がわかる)\n",
    "processor_description = processor.jobs[-1].describe()\n",
    "print(processor_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_uri = processor_description['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "test_data_uri = processor_description['ProcessingOutputConfig']['Outputs'][1]['S3Output']['S3Uri']\n",
    "print(f'train_data_uri: {train_data_uri}')\n",
    "print(f'test_data_uri: {test_data_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理結果の格納先を設定ファイルに書き込んで次の処理に連携\n",
    "with open(\"./setting.yaml\", mode='a') as f:\n",
    "    f.write('train_data_uri: ' + train_data_uri +'\\n')\n",
    "    f.write('test_data_uri: ' + test_data_uri + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
