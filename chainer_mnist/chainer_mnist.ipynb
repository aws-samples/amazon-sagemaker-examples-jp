{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chainer の学習と推論を SageMaker で行う\n",
        "\n",
        "MNISTデータセットを対象にSageMakerとChainerを利用してMLPの学習と推論を行います。学習の方法として以下の3種類を試します。\n",
        "- 単一または複数ノードによる学習: 高性能なトレーニングインスタンスを1つまたは複数立ち上げて学習を行います。\n",
        "- ハイパーパラメータ最適化: 単一ノードにおける学習でHPO (Hyper-Parameter Optimization: ハイパーパラメータ最適化）を行います。\n",
        "- ローカルモード: ノートブックインスタンスで学習します。追加のインスタンス立ち上げが不要で、開発時のデバッグに有用です。\n",
        "\n\n",
        "## 目次\n",
        "1. [準備](#準備)\n",
        "2. [データの取得とS3へのアップロード](#データの取得とS3へのアップロード)\n",
        "3. [エントリーポイント](#エントリーポイント)\n",
        "4. [モデルの学習](#モデルの学習)\n",
        "    1. [単一または複数ノードによる学習](#単一または複数ノードによる学習)\n",
        "    2. [ハイパーパラメータの最適化](#ハイパーパラメータの最適化)\n",
        "    3. [ローカルモード](#ローカルモード)\n",
        "5. [学習結果の可視化](#学習結果の可視化)\n",
        "6. [ハイパーパラメータのチューニング結果](#ハイパーパラメータのチューニング結果)\n",
        "7. [モデルの推論を実行](#モデルの推論を実行)\n",
        "8. [エンドポイントの削除](#エンドポイントの削除)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "\nローカルモードを実行するため、いくつかのパッケージを事前インストールする必要があります。そのためのスクリプト`setup.sh`を用意しているので実行しましょう。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!sh setup.sh"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの取得とS3へのアップロード\n",
        "\n",
        "ここでは、`Chainer` でサポートされている関数を使って、MNIST データをダウンロードします。SageMaker の学習時に利用するデータは、S3 に置く必要があります。ここでは、ローカルにダウンロードした MNIST データを npz 形式で固めてから、SageMaker のラッパー関数を使って S3 にアップロードします。\n",
        "\nデフォルトでは SageMaker は `sagemaker-{region}-{your aws account number}` というバケットを使用します。当該バケットがない場合には、自動で新しく作成します。`upload_data()` メソッドの引数に bucket=XXXX という形でデータを配置するバケットを指定することも可能です。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "sagemaker_session = sagemaker.Session()\n",
        "role = get_execution_role()\n",
        "\n",
        "# Download MNIST dataset\n",
        "train, test = chainer.datasets.get_mnist()\n",
        "\n",
        "# Extract data and labels from dataset \n",
        "train_images = np.array([data[0] for data in train])\n",
        "train_labels = np.array([data[1] for data in train])\n",
        "test_images = np.array([data[0] for data in test])\n",
        "test_labels = np.array([data[1] for data in test])\n",
        "\n",
        "# Save the data and labels as .npz into local directories and upload them to S3\n",
        "try:\n",
        "    os.makedirs('/tmp/data/train')\n",
        "    os.makedirs('/tmp/data/test')\n",
        "\n",
        "    np.savez('/tmp/data/train/train.npz', images=train_images, labels=train_labels)\n",
        "    np.savez('/tmp/data/test/test.npz', images=test_images, labels=test_labels)\n",
        "\n",
        "    train_input = sagemaker_session.upload_data(\n",
        "        path=os.path.join('/tmp/data', 'train'),\n",
        "        key_prefix='notebook/chainer/mnist')\n",
        "    test_input = sagemaker_session.upload_data(\n",
        "        path=os.path.join('/tmp/data', 'test'),\n",
        "        key_prefix='notebook/chainer/mnist')\n",
        "finally:\n",
        "    shutil.rmtree('/tmp/data')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## エントリーポイント\n",
        "\n",
        "SageMakerで、Chainer、Tensorflowなどのフレームワークを利用して深層学習を行うためには、このnotebook以外に**エントリーポイントを作成する必要があります**。エントリーポイントとはモデルや学習方法を記述した.pyファイルで、このnotebookには`chainer_mnist.py`というエントリーポイントを同じフォルダに用意しています。ノートブックインスタンスでfit関数を呼び出すと、エントリーポイントに沿って学習が行われます。\n",
        "\n",
        "chainerを利用する場合は、エントリーポイントの`__main__`関数内にモデルの記述や学習方法を記載すればよく、SageMakerを使う以前のChainerのコードを概ねそのまま利用することができます。また、環境変数経由で入力データの場所や GPU の数などを取得することが可能です。これは `argparse` 経由で `main` 関数内で受け取ることができます。詳細は[こちら](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/chainer/README.rst)をご覧ください。\n",
        "\n",
        "また推論時の処理は、`model_fn` で学習済みモデルをロードする部分だけ記述する必要があります。その他オプションで、前処理、推論処理、後処理部分を `input_fn`、 `predict_fn`、 `output_fn` で書くこともできます。デフォルトでは、`application/x-npy` コンテントタイプで指定される、NumPy 配列を入力として受け取ります。 \n",
        "\n以下のセルを実行してエントリーポイントの中身を表示してみます。すると、`class MLP(chainer.Chain)`といったモデルの定義、`__main__`の中に学習のコードが書かれていることがわかります。また、chainerMNのoptimizerを使用して分散学習を行うようになっています。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize 'chainer_mnist.py'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの学習\n",
        "\n",
        "`Estimator` クラスの子クラスの `Chainer` オブジェクトを作成し、`fit()` メソッドで学習ジョブを実行します。 `entry_point` で指定したローカルのスクリプトが、学習用のコンテナ内で実行されます。また合わせてローカルの `source_dir` を指定することで、依存するスクリプト群をコンテナにコピーして、学習時に使用することが可能です。\n",
        "\n",
        "### 単一または複数ノードによる学習\n",
        "\n単一ノードで学習したい場合は、`train_instance_count=1`として、学習用インスタンスを`instance_type`に指定します。複数ノードによる学習は、`train_instance_count`を1より大きくすることで実行できます。複数ノードの場合には、分散学習となるようにエントリーポイントにChainerMNを利用した実装が必要になります。あとで学習の結果を参照するためにジョブの名前を記録しておきます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "from sagemaker.chainer.estimator import Chainer\n",
        "\n",
        "instance_type = 'ml.m4.xlarge'\n",
        "\n",
        "chainer_estimator = Chainer(entry_point='chainer_mnist.py', role=role,\n",
        "                            train_instance_count=1, train_instance_type=instance_type,\n",
        "                            framework_version='5.0.0',\n",
        "                            hyperparameters={'epochs': 3, 'batch-size': 128})\n",
        "\n",
        "chainer_estimator.fit({'train': train_input, 'test': test_input})\n",
        "\n",
        "# Keep the job name for checking training loss later \n",
        "training_job = chainer_estimator.latest_training_job.name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ハイパーパラメータの最適化\n",
        "\n",
        "ハイパーパラメータの最適化は、fitする前に、以下のような処理を書くことによって実行できます。\n",
        "\n",
        "- ハイパーパラメータの探索条件の設定\n",
        "    - カテゴリ変数、連続変数、離散変数かどうか、探索範囲の指定を行います。\n",
        "- ハイパーパラメータを選択する基準（以下では、バリデーションデータに対する精度で選択）\n",
        "    - エントリーポイント内のPrintReportでバリデーションデータに対する精度を出力 \n",
        "    - ログからバリデーションデータに対する精度のみを抽出する正規表現を記述  \n",
        "    \n",
        "- 上記の探索範囲、選択基準、チューニングのために実行するジョブ数などを指定してHyperparameterTunerを定義\n",
        "\n",
        "ハンズオンの時間の都合上、以下では最適化のアルゴリズムをSGDかAdamのどちらかを選択するだけのチューニングを行います。\n",
        "チューニングのジョブを以下のページで確認することができます。`Completed`になるまで5分程度かかりますので、待たずに次のローカルモードに進みましょう。  \n",
        "https://ap-northeast-1.console.aws.amazon.com/sagemaker/home?region=ap-northeast-1#/hyper-tuning-jobs"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from sagemaker.chainer.estimator import Chainer\n",
        "instance_type = 'ml.m4.xlarge'\n",
        "chainer_estimator = Chainer(entry_point='chainer_mnist.py', role=role,\n",
        "                            train_instance_count=1, train_instance_type=instance_type,\n",
        "                            framework_version='5.0.0',\n",
        "                            hyperparameters={'epochs':3, 'batch_size': 128})\n",
        "\n",
        "###Setting for hyper paramter optimization###\n",
        "from sagemaker.tuner import HyperparameterTuner,  CategoricalParameter, ContinuousParameter, IntegerParameter\n",
        "\n",
        "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'Adam'])}\n",
        "'''\n",
        "An example of further tuning:\n",
        "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'Adam']),\n",
        "                          'learning_rate': ContinuousParameter(0.01, 0.2),\n",
        "                          'num_epoch': IntegerParameter(3, 5)}\n",
        "'''\n",
        "\n",
        "objective_metric_name = 'Validation-accuracy'\n",
        "metric_definitions = [{'Name': 'Validation-accuracy',\n",
        "                       'Regex': 'validation/main/accuracy=([0-9\\\\.]+)'}]\n",
        "\n",
        "tuner = HyperparameterTuner(chainer_estimator,\n",
        "                            objective_metric_name,\n",
        "                            hyperparameter_ranges,\n",
        "                            metric_definitions,\n",
        "                            max_jobs=2,\n",
        "                            max_parallel_jobs=2)\n",
        "##################################\n",
        "\n",
        "tuner.fit({'train': train_input, 'test': test_input})\n",
        "\ntraining_job_tuning = tuner.latest_tuning_job.name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ローカルモード\n",
        "\nノートブックインスタンスのCPUで学習する場合は`instance_type = 'local'`、GPUで学習する場合は`local_gpu`を指定します。インスタンス数は、ノートブックインスタンスの数、すなわち1になるため、 `train_instance_count`に指定された値が1より大きい場合も1として扱われます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "from sagemaker.chainer.estimator import Chainer\n",
        "\n",
        "instance_type = 'local'\n",
        "\n",
        "chainer_estimator = Chainer(entry_point='chainer_mnist.py', role=role,\n",
        "                            train_instance_count=1, train_instance_type=instance_type,\n",
        "                            framework_version='5.0.0',\n",
        "                            hyperparameters={'epochs': 3, 'batch_size': 128})\n",
        "\nchainer_estimator.fit({'train': train_input, 'test': test_input})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータのチューニング結果\n",
        "以下でチューニングのジョブが`complete`になっていることを確認します。チューニングのジョブの表で、先ほど実行したジョブの名前をクリックすると、トレーニングジョブのページに移動します。SGDとAdamのそれぞれの最適化を実行したジョブの結果が表示されており、それぞれの検証スコア（バリデーションデータに対する精度）が表示されていると思います。  \n",
        "https://ap-northeast-1.console.aws.amazon.com/sagemaker/home?region=ap-northeast-1#/hyper-tuning-jobs  \n",
        "\n`describe_training_job`を利用することで、ジョブの詳細を辞書形式で見ることができます。特に、チューニングジョブの詳細を見ることによって、ハイパーパラメータのチューニング結果を知ることができます。例えば、ハイパーパラメータ最適化によって、選択されたOptimizerを知りたい場合は、辞書の\\['HyperParameters'\\]\\['Optimizer'\\]を見ます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "desc = tuner.sagemaker_session.sagemaker_client. \\\n",
        "           describe_training_job(TrainingJobName=tuner.best_training_job())\n",
        "selected_optimizer = desc['HyperParameters']['optimizer']\n",
        "print(selected_optimizer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの推論を実行\n",
        "\n\n推論を行うために学習したモデルをデプロイします。ここでは、ハイパーパラメータをチューニングした結果からデプロイしましょう。`deploy()` メソッドでは、デプロイ先エンドポイントのインスタンス数、インスタンスタイプを指定します。こちらもインスタンスタイプを `local` にすることで，このインスタンス内にエンドポイントを作成します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "instance_type = 'ml.m4.xlarge'\n",
        "predictor = tuner.deploy(initial_instance_count=1, instance_type=instance_type)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "デプロイが終わったら実際に手書き文字認識を行ってみましょう。最初はランダムに5枚選んで推論をしてみます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_samples = 5\n",
        "indices = random.sample(range(test_images.shape[0] - 1), num_samples)\n",
        "images, labels = test_images[indices], test_labels[indices]\n",
        "\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1,num_samples,i+1)\n",
        "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(labels[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "prediction = predictor.predict(images)\n",
        "predicted_label = prediction.argmax(axis=1)\n",
        "print('The predicted labels are: {}'.format(predicted_label))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると、HTMLのcanvasを表示して、枠内に手書きの数字を書くことができます。さらに次のセルを実行すると、キャンバスに書かれた数字に対して、エンドポイントで予測が実行されます。"
      ],
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML(open(\"input.html\").read())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = np.array(data, dtype=np.float32)\n",
        "prediction = predictor.predict(image)\n",
        "predicted_label = prediction.argmax(axis=1)[0]\n",
        "print('What you wrote is: {}'.format(predicted_label))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## エンドポイントの削除\n",
        "\n全て終わったら，エンドポイントを削除します．"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.delete_endpoint()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_chainer_p36",
      "language": "python",
      "name": "conda_chainer_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
